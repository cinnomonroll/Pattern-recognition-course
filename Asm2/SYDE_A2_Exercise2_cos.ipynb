{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(torch.cuda.get_device_properties(i).name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset, False makes it return the data as a NumPy array\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False, parser='liac-arff')\n",
    "\n",
    "# Flatten the images\n",
    "X = mnist.data\n",
    "y = mnist.target\n",
    "#print(X.shape) #(70000, 784)\n",
    "\n",
    "# Split the data\n",
    "X_train, y_train = X[:60000], y[:60000] #X_train.shape (60000, 784)\n",
    "X_test, y_test = X[60000:], y[60000:]\n",
    "\n",
    "# Convert labels to integers\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def kmeans_cosine(X, k):\n",
    "    # Normalize the data to unit length\n",
    "    X_norm = normalize(X)\n",
    "\n",
    "    # Apply k-means with cosine distance\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0).fit(X_norm)\n",
    "\n",
    "    # Get labels and centroids\n",
    "    labels = kmeans.labels_\n",
    "    centroids = kmeans.cluster_centers_\n",
    "\n",
    "    return labels, centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\AIP1\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consistency for k=5: 0.5348332465334867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\AIP1\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consistency for k=10: 0.6470038256087342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\AIP1\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consistency for k=20: 0.7456912065105913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\AIP1\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consistency for k=40: 0.8170488682569534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\AIP1\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consistency for k=200: 0.9181505413656041\n"
     ]
    }
   ],
   "source": [
    "def cluster_consistency(labels, y_train, k):\n",
    "    Q = 0\n",
    "\n",
    "    for i in range(k):\n",
    "        \n",
    "        cluster_labels = y_train[labels == i]\n",
    "        class_counts = np.bincount(cluster_labels)\n",
    "\n",
    "        mi = np.max(class_counts)\n",
    "        Ni = len(cluster_labels)\n",
    "\n",
    "        Qi = mi / Ni\n",
    "        Q += Qi\n",
    "    Q /=k\n",
    "\n",
    "    return Q\n",
    "\n",
    "#Train set\n",
    "\n",
    "k_values = [5, 10, 20, 40, 200]\n",
    "\n",
    "for k in k_values:\n",
    "    labels, centroids = kmeans_cosine(X_train, k) ####\n",
    "    Q = cluster_consistency(labels, y_train, k)\n",
    "    print(f\"Consistency for k={k}: {Q}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\AIP1\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consistency for test data with k=5: 0.5369658666209592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\AIP1\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consistency for test data with k=10: 0.6493407470345633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\AIP1\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consistency for test data with k=20: 0.7486155096417354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\AIP1\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consistency for test data with k=40: 0.8235276208242197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\AIP1\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consistency for test data with k=200: 0.9198500728384915\n"
     ]
    }
   ],
   "source": [
    "#Test set\n",
    "k_values = [5, 10, 20, 40, 200]\n",
    "X_train_norm = normalize(X_train)\n",
    "X_test_norm = normalize(X_test)\n",
    "\n",
    "for k in k_values:\n",
    "    # Apply k-means with cosine distance\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0).fit(X_train_norm)\n",
    "\n",
    "    # Apply the k-means model to the test data\n",
    "    labels_test = kmeans.predict(X_test_norm)\n",
    "\n",
    "    # Calculate the consistency for the test data\n",
    "    Q_test = cluster_consistency(labels_test, y_test, k)\n",
    "    print(f\"Consistency for test data with k={k}: {Q_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\AIP1\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internal distance for k=5: 29785.909253899536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\AIP1\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internal distance for k=10: 26443.18348876443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\AIP1\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internal distance for k=20: 23562.846742489706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\AIP1\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internal distance for k=40: 21209.92920703419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\AIP1\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internal distance for k=200: 16937.056012729696\n"
     ]
    }
   ],
   "source": [
    "#Use another distance measure for evaluating the cluster consistency\n",
    "def cluster_internal_distance(X, labels, centroids):\n",
    "    J = 0\n",
    "    for i in range(len(centroids)):\n",
    "        cluster_points = X[labels == i]\n",
    "        distances = np.linalg.norm(cluster_points - centroids[i], axis=1)\n",
    "        J += np.sum(distances**2)\n",
    "    return J\n",
    "\n",
    "for k in k_values:\n",
    "    # Apply k-means with cosine distance\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0).fit(X_train_norm)\n",
    "    labels = kmeans.labels_\n",
    "    centroids = kmeans.cluster_centers_\n",
    "\n",
    "    # Calculate the internal distance for the clusters\n",
    "    J = cluster_internal_distance(X_train_norm, labels, centroids) #the result is smaller the better\n",
    "    print(f\"Internal distance for k={k}: {J}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\AIP1\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consistency for train data with k=5: 0.4636483374321534\n",
      "Internal distance for train k=5: 5789.59061535925\n",
      "Consistency for test data with k=5: 0.4668687781581492\n",
      "Internal distance for test k=5: 965.9782852643928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\AIP1\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consistency for train data with k=10: 0.6001417286376383\n",
      "Internal distance for train k=10: 3712.477430035757\n",
      "Consistency for test data with k=10: 0.5991502338696233\n",
      "Internal distance for test k=10: 626.9490124379665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\AIP1\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consistency for train data with k=20: 0.6654042604547693\n",
      "Internal distance for train k=20: 2597.8075699815704\n",
      "Consistency for test data with k=20: 0.680306140999449\n",
      "Internal distance for test k=20: 437.0491594797717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\AIP1\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consistency for train data with k=40: 0.6976721160282737\n",
      "Internal distance for train k=40: 1876.2938096451476\n",
      "Consistency for test data with k=40: 0.6969698015121765\n",
      "Internal distance for test k=40: 316.82006091035737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\AIP1\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consistency for train data with k=200: 0.7385425704488598\n",
      "Internal distance for train k=200: 927.3869154714818\n",
      "Consistency for test data with k=200: 0.7432973742491391\n",
      "Internal distance for test k=200: 161.89169633718842\n"
     ]
    }
   ],
   "source": [
    "# Apply PCA to the training data\n",
    "pca = PCA(n_components=5)  # You can adjust the number of components\n",
    "X_train_norm = normalize(X_train)\n",
    "X_train_pca = pca.fit_transform(X_train_norm)\n",
    "\n",
    "k_values = [5, 10, 20, 40, 200]\n",
    "\n",
    "for k in k_values:\n",
    "    # Apply k-means with cosine distance\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0).fit(X_train_pca)\n",
    "\n",
    "    labels = kmeans.labels_\n",
    "    Q_train = cluster_consistency(kmeans.labels_, y_train, k)\n",
    "    print(f\"Consistency for train data with k={k}: {Q_train}\")\n",
    "    J = cluster_internal_distance(X_train_pca, kmeans.labels_, kmeans.cluster_centers_)\n",
    "    print(f\"Internal distance for train k={k}: {J}\")\n",
    "\n",
    "    # Apply the k-means model to the test data\n",
    "    X_test_pca = pca.transform(X_test_norm)\n",
    "    labels_test = kmeans.predict(X_test_pca)\n",
    "\n",
    "    # Calculate the consistency for the test data\n",
    "    Q_test = cluster_consistency(labels_test, y_test, k)\n",
    "    print(f\"Consistency for test data with k={k}: {Q_test}\")\n",
    "\n",
    "    # Calculate the internal distance for the clusters\n",
    "    J = cluster_internal_distance(X_test_pca, labels_test, kmeans.cluster_centers_)\n",
    "    print(f\"Internal distance for test k={k}: {J}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. (5 pts) Which k value produces the best results? Explain. Can the results from cluster consistency be misleading? Explain. [HINT Intuitively, what k value should produce the best results on the MNIST dataset?]\n",
    "\n",
    "\n",
    "\n",
    "k=200 generated the highest consistency value of 0.9181505413656041 for training set and 0.9198500728384915 for testing set, so it can be said that k=200 produced the best result. This is because as the value of k increases, the size of each cluster (i.e., the number of points it contains) usually decreases. Therefore, the proportion of the most common category in each cluster may increase, leading to an improvement in consistency.\n",
    "However, this result may be misleading. Although consistency is a useful indicator, it does not fully reflect the quality of the clusters. For example, if the value of k is too large, although the consistency may be high, this may be just because each cluster contains only a few points. In addition, if the value of k equals the total number of data points, then each data point will become its own cluster, and the consistency will reach the maximum value of 1, but this does not mean that we have obtained a good clustering result.\n",
    "For the MNIST dataset, intuitively, the best value of k should be 10, because the MNIST dataset contains 10 categories of handwritten digits (0 to 9). However, due to the distribution and variability of the data, the actual optimal value of k may be different.\n",
    "\n",
    "5. (10 pts) What can you do to further validate your results if the cluster consistency metric is not working?\n",
    "Can you use the objective function defined in the class to find out the internal cluster distance of the data points from the mean? How can this objective help determine any misleading clustering results?\n",
    "Explain and demonstrate this method on the clustering results of the previous steps.\n",
    "\n",
    "\n",
    "\n",
    "I will use internal cluster distance and apply pca on dataset to further validate the results. Using internal cluster distance to calculate the distance between each point within a cluster and the center of that cluster. The smaller the value of this objective function, the closer each point in a cluster is to the center of that cluster, that is to say, the higher the compactness of the cluster. Therefore, this objective function can help us identify possible misleading clustering results. For example, if the internal distance of a cluster is large, it may mean that the cluster contains multiple different sub-clusters, so we may need to increase the value of k to get better clustering results. \n",
    "When k=200, the internal distance reached the minimum value of 16937.056012729696, so we can say that k=200 produced the best result. However, please note that this does not mean that k=200 is the optimal number of clusters, because a too large k value may lead to overclustering.\n",
    "After applying PCA, k=200 still gets the best results (see results in jupyter notebook). I notice that if k equals to the number of data points, the cluster consistency will be 1 (the highest score), and internal distance will be 0 (the lowest score), which means that it’s overclustering. Besides, the internal distance drops more when goes from k = 5 to k = 10 than k =10 to k =20. Therefore, set a threshold for internal distance will be a feasible way to give the best fit. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIP1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
